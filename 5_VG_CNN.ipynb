{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torchvision.io import read_image\n",
    "import warnings\n",
    "from torchvision import transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Networks Laboratory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.to_pil = transforms.ToPILImage()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "\n",
    "        label = torch.tensor(self.img_labels.iloc[idx, 1:].astype(float).values, dtype=torch.float32)\n",
    "\n",
    "        img_name = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "                \n",
    "\n",
    "        image = read_image(img_name)\n",
    "        \n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(self.to_pil(image))\n",
    "\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return image, label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.path.join('data', 'screenshots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScreenDataset = CustomImageDataset(annotations_file=os.path.join(folder, 'image_labels.csv'), img_dir=os.path.join(folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8 \n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(ScreenDataset, [train_size, 1-train_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[ 48,  60, 112,  ..., 145, 136, 136],\n",
       "           [102, 128, 150,  ..., 129, 118, 116],\n",
       "           [169, 174, 153,  ..., 107,  97,  95],\n",
       "           ...,\n",
       "           [215, 212, 214,  ..., 237, 245, 244],\n",
       "           [210, 210, 211,  ..., 255, 255, 255],\n",
       "           [216, 215, 214,  ..., 255, 255, 255]],\n",
       " \n",
       "          [[ 32,  45,  95,  ..., 179, 171, 171],\n",
       "           [ 95, 121, 140,  ..., 170, 159, 160],\n",
       "           [178, 182, 156,  ..., 163, 153, 153],\n",
       "           ...,\n",
       "           [116, 113, 115,  ..., 181, 189, 190],\n",
       "           [111, 111, 112,  ..., 208, 207, 207],\n",
       "           [117, 116, 115,  ..., 205, 207, 207]],\n",
       " \n",
       "          [[  6,  12,  49,  ..., 181, 175, 175],\n",
       "           [ 49,  69,  81,  ..., 172, 163, 163],\n",
       "           [ 95,  97,  69,  ..., 162, 154, 154],\n",
       "           ...,\n",
       "           [ 85,  82,  83,  ..., 156, 164, 164],\n",
       "           [ 80,  80,  80,  ..., 184, 183, 183],\n",
       "           [ 86,  85,  83,  ..., 181, 183, 183]]],\n",
       " \n",
       " \n",
       "         [[[ 66,  75,  84,  ...,  88,  84,  84],\n",
       "           [ 73,  67,  76,  ...,  94,  91,  89],\n",
       "           [ 76,  66,  71,  ..., 102, 105, 102],\n",
       "           ...,\n",
       "           [ 34,  28,  36,  ..., 108, 116, 116],\n",
       "           [ 32,  28,  29,  ..., 139, 131, 131],\n",
       "           [ 32,  28,  29,  ..., 142, 134, 134]],\n",
       " \n",
       "          [[ 59,  69,  82,  ...,  82,  76,  77],\n",
       "           [ 78,  72,  80,  ...,  83,  81,  81],\n",
       "           [108,  94,  88,  ...,  78,  89,  90],\n",
       "           ...,\n",
       "           [ 44,  38,  46,  ..., 130, 137, 138],\n",
       "           [ 43,  39,  40,  ..., 154, 146, 146],\n",
       "           [ 43,  39,  40,  ..., 154, 146, 146]],\n",
       " \n",
       "          [[ 93, 105, 121,  ..., 144, 149, 155],\n",
       "           [108, 104, 115,  ..., 143, 150, 156],\n",
       "           [129, 116, 116,  ..., 136, 152, 156],\n",
       "           ...,\n",
       "           [ 93,  87,  95,  ..., 171, 180, 179],\n",
       "           [ 89,  85,  86,  ..., 183, 177, 175],\n",
       "           [ 88,  84,  86,  ..., 178, 170, 170]]],\n",
       " \n",
       " \n",
       "         [[[ 59,  61,  64,  ...,  60,  59,  59],\n",
       "           [ 62,  62,  61,  ...,  60,  59,  59],\n",
       "           [ 58,  61,  64,  ...,  60,  58,  58],\n",
       "           ...,\n",
       "           [ 81,  82,  84,  ...,  84,  82,  82],\n",
       "           [ 82,  81,  83,  ...,  79,  82,  82],\n",
       "           [ 82,  81,  83,  ...,  79,  82,  82]],\n",
       " \n",
       "          [[ 59,  61,  64,  ...,  62,  61,  61],\n",
       "           [ 62,  62,  61,  ...,  62,  61,  61],\n",
       "           [ 59,  63,  66,  ...,  62,  60,  60],\n",
       "           ...,\n",
       "           [ 84,  85,  87,  ...,  86,  84,  84],\n",
       "           [ 85,  84,  86,  ...,  81,  84,  84],\n",
       "           [ 85,  84,  86,  ...,  81,  84,  84]],\n",
       " \n",
       "          [[ 59,  61,  62,  ...,  61,  60,  60],\n",
       "           [ 62,  62,  61,  ...,  61,  60,  60],\n",
       "           [ 61,  62,  65,  ...,  61,  59,  59],\n",
       "           ...,\n",
       "           [ 75,  76,  78,  ...,  73,  71,  71],\n",
       "           [ 76,  75,  77,  ...,  68,  71,  71],\n",
       "           [ 76,  75,  77,  ...,  68,  71,  71]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 82,  80,  86,  ...,  56,  60,  60],\n",
       "           [ 92,  92,  97,  ...,  69,  66,  66],\n",
       "           [ 55,  59,  58,  ...,  43,  48,  48],\n",
       "           ...,\n",
       "           [127, 132, 121,  ..., 127, 127, 127],\n",
       "           [128, 127, 126,  ..., 127, 127, 127],\n",
       "           [128, 127, 127,  ..., 127, 127, 127]],\n",
       " \n",
       "          [[110, 108, 114,  ...,  82,  85,  84],\n",
       "           [118, 118, 123,  ...,  93,  90,  89],\n",
       "           [ 76,  80,  79,  ...,  65,  67,  67],\n",
       "           ...,\n",
       "           [126, 133, 123,  ..., 128, 128, 128],\n",
       "           [128, 128, 129,  ..., 128, 128, 128],\n",
       "           [128, 128, 128,  ..., 128, 128, 128]],\n",
       " \n",
       "          [[131, 129, 138,  ..., 117, 126, 128],\n",
       "           [133, 133, 140,  ..., 117, 118, 120],\n",
       "           [ 79,  85,  84,  ...,  63,  71,  73],\n",
       "           ...,\n",
       "           [  0,   5,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "         [[[191, 161, 120,  ..., 225, 213, 213],\n",
       "           [200, 178, 140,  ..., 217, 207, 207],\n",
       "           [218, 200, 161,  ..., 202, 204, 204],\n",
       "           ...,\n",
       "           [194, 194, 195,  ..., 195, 200, 200],\n",
       "           [192, 192, 190,  ..., 195, 201, 201],\n",
       "           [192, 192, 190,  ..., 195, 201, 202]],\n",
       " \n",
       "          [[229, 203, 171,  ..., 225, 213, 213],\n",
       "           [235, 216, 186,  ..., 218, 208, 208],\n",
       "           [244, 229, 197,  ..., 210, 209, 209],\n",
       "           ...,\n",
       "           [213, 213, 214,  ..., 208, 209, 209],\n",
       "           [211, 211, 212,  ..., 208, 210, 210],\n",
       "           [211, 211, 212,  ..., 208, 210, 211]],\n",
       " \n",
       "          [[248, 225, 200,  ..., 225, 213, 213],\n",
       "           [254, 237, 212,  ..., 220, 210, 210],\n",
       "           [255, 245, 219,  ..., 213, 213, 213],\n",
       "           ...,\n",
       "           [228, 228, 228,  ..., 214, 214, 214],\n",
       "           [226, 226, 226,  ..., 214, 215, 215],\n",
       "           [226, 226, 226,  ..., 214, 215, 216]]],\n",
       " \n",
       " \n",
       "         [[[136, 139, 143,  ..., 189, 203, 205],\n",
       "           [139, 142, 146,  ..., 193, 210, 210],\n",
       "           [144, 147, 151,  ..., 199, 200, 200],\n",
       "           ...,\n",
       "           [ 75,  87,  88,  ..., 115, 116, 117],\n",
       "           [ 81,  85,  88,  ..., 125, 125, 127],\n",
       "           [ 91,  95,  98,  ..., 124, 131, 134]],\n",
       " \n",
       "          [[ 64,  67,  71,  ..., 128, 141, 140],\n",
       "           [ 67,  70,  74,  ..., 135, 148, 148],\n",
       "           [ 72,  75,  79,  ..., 142, 140, 140],\n",
       "           ...,\n",
       "           [ 44,  53,  49,  ...,  90,  88,  88],\n",
       "           [ 58,  59,  60,  ..., 103, 101, 100],\n",
       "           [ 73,  74,  75,  ..., 105, 107, 108]],\n",
       " \n",
       "          [[128, 131, 134,  ..., 169, 182, 180],\n",
       "           [131, 134, 137,  ..., 175, 187, 185],\n",
       "           [136, 139, 142,  ..., 177, 174, 174],\n",
       "           ...,\n",
       "           [161, 173, 174,  ..., 207, 207, 207],\n",
       "           [166, 168, 173,  ..., 214, 213, 213],\n",
       "           [175, 179, 183,  ..., 212, 217, 218]]]], dtype=torch.uint8),\n",
       " tensor([[ 3.],\n",
       "         [ 7.],\n",
       "         [18.],\n",
       "         [11.],\n",
       "         [ 0.],\n",
       "         [15.],\n",
       "         [ 2.],\n",
       "         [ 9.],\n",
       "         [13.],\n",
       "         [ 0.],\n",
       "         [15.],\n",
       "         [ 0.],\n",
       "         [ 3.],\n",
       "         [ 3.],\n",
       "         [15.],\n",
       "         [ 9.],\n",
       "         [13.],\n",
       "         [15.],\n",
       "         [ 0.],\n",
       "         [13.],\n",
       "         [12.],\n",
       "         [ 2.],\n",
       "         [16.],\n",
       "         [11.],\n",
       "         [ 9.],\n",
       "         [ 9.],\n",
       "         [17.],\n",
       "         [10.],\n",
       "         [ 8.],\n",
       "         [15.],\n",
       "         [17.],\n",
       "         [14.]])]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=90x90>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topil = transforms.ToPILImage()\n",
    "topil(next(iter(train_dataloader))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.path.join('data','screenshots')\n",
    "labels_map = pd.read_csv(os.path.join(folder,'genre_labels.csv'))\n",
    "labels_map = labels_map.to_dict()['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, labels_map):\n",
    "        super(Net, self).__init__()\n",
    "        self.apply(self._initialize_weights)\n",
    "        num_classes = len(labels_map)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=(5,5))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5,5))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 19 * 19, 200)  \n",
    "        self.fc2 = nn.Linear(200, 300)\n",
    "        self.fc3 = nn.Linear(300, 100)\n",
    "        self.fc4 = nn.Linear(100, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu(self.conv1(x.float())))\n",
    "        x = self.pool2(self.relu(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def _initialize_weights(self, layer):\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            init.xavier_uniform_(layer.weight)\n",
    "            if layer.bias is not None:\n",
    "                init.zeros_(layer.bias)\n",
    "\n",
    "model = Net(labels_map=labels_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=5776, out_features=200, bias=True)\n",
       "  (fc2): Linear(in_features=200, out_features=300, bias=True)\n",
       "  (fc3): Linear(in_features=300, out_features=100, bias=True)\n",
       "  (fc4): Linear(in_features=100, out_features=21, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "  \n",
    "  size = len(dataloader.dataset)\n",
    "  for batch, (X, y) in enumerate(dataloader):\n",
    "    X, y = X.to(device), y.to(device).long()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pred = model(X)\n",
    "\n",
    "\n",
    "\n",
    "    loss = loss_fn(pred, y.squeeze(1))\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "  size = len(dataloader.dataset)\n",
    "  num_batches = len(dataloader)\n",
    "  test_loss, correct = 0, 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for X, y in dataloader:\n",
    "      X, y = X.to(device), y.to(device)\n",
    "      pred = model(X)\n",
    "\n",
    "      test_loss += loss_fn(pred, y).item()\n",
    "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "  test_loss /= num_batches\n",
    "  correct /= size\n",
    "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "  return 100*correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "batch_size = 16\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[199], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m     \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     accuracies\u001b[38;5;241m.\u001b[39mappend(test_loop(test_dataloader, model, loss_fn))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[197], line 4\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_loop\u001b[39m(dataloader, model, loss_fn, optimizer):\n\u001b[0;32m      3\u001b[0m   size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m----> 4\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m batch, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[0;32m      5\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[0;32m      7\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\dange\\anaconda3\\envs\\dnn\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\dange\\anaconda3\\envs\\dnn\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\dange\\anaconda3\\envs\\dnn\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\dange\\anaconda3\\envs\\dnn\\lib\\site-packages\\torch\\utils\\data\\dataset.py:399\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\Users\\dange\\anaconda3\\envs\\dnn\\lib\\site-packages\\torch\\utils\\data\\dataset.py:399\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[1;32mIn[188], line 21\u001b[0m, in \u001b[0;36mCustomImageDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     16\u001b[0m label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_labels\u001b[38;5;241m.\u001b[39miloc[idx, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     18\u001b[0m img_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_labels\u001b[38;5;241m.\u001b[39miloc[idx, \u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 21\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mread_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m     25\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_pil(image))\n",
      "File \u001b[1;32mc:\\Users\\dange\\anaconda3\\envs\\dnn\\lib\\site-packages\\torchvision\\io\\image.py:258\u001b[0m, in \u001b[0;36mread_image\u001b[1;34m(path, mode)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing():\n\u001b[0;32m    257\u001b[0m     _log_api_usage_once(read_image)\n\u001b[1;32m--> 258\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m decode_image(data, mode)\n",
      "File \u001b[1;32mc:\\Users\\dange\\anaconda3\\envs\\dnn\\lib\\site-packages\\torchvision\\io\\image.py:52\u001b[0m, in \u001b[0;36mread_file\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing():\n\u001b[0;32m     51\u001b[0m     _log_api_usage_once(read_file)\n\u001b[1;32m---> 52\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\dange\\anaconda3\\envs\\dnn\\lib\\site-packages\\torch\\_ops.py:755\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    751\u001b[0m     \u001b[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;66;03m# is still callable from JIT\u001b[39;00m\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[0;32m    754\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[1;32m--> 755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(kwargs \u001b[38;5;129;01mor\u001b[39;00m {}))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "accuracies = []\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    accuracies.append(test_loop(test_dataloader, model, loss_fn))\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
